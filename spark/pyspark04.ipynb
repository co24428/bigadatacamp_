{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reference\n",
    "- https://books.google.co.kr/books?id=HVQoDwAAQBAJ&pg=PA84&lpg=PA84&dq=births_transformed+%3D+births_transformed.select(exprs_YNU)&source=bl&ots=tLNsHpKdfH&sig=ACfU3U37yj0SiQWLB-DgXvOuT1toOs4keQ&hl=ko&sa=X&ved=2ahUKEwjissX9v5HpAhWS7WEKHbfMAkIQ6AEwAHoECAoQAQ#v=onepage&q&f=false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLlib package of PySpark  \n",
    "스파크 2.0부터 ML 패키지는 데이터프레임에 대해 작동\n",
    "MLlist 패키지는 RDD에 대해서 작동 함.  \n",
    "\n",
    "MLlib은 전체적으로 크게 세단계의 머신러닝 기능으로 구분 된다.  \n",
    "- 데이터 전처리 : 피처 추출, 변형, 선택, 카테고리 피처에 대한 해석, 자연어 처리  \n",
    "- 머신러닝 알고리즘 : 몇몇 유명, 고급 레벨인 회귀, 분류, 군집 알고리즘 지원  \n",
    "- 유틸리티 : 기술통계, 카이스퀘어(ChiSquare)테스트, 선행대수, 모델평가  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\bigdata\\\\spark-2.4.5-bin-hadoop2.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark, pyspark\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf \n",
    "from pyspark.sql import SparkSession \n",
    "conf = pyspark.SparkConf() \\\n",
    "                .setAppName('appName') \\\n",
    "                .setMaster('local[*]')\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "US 2014 ~ 2015 출생 데이터의 일부  \n",
    "원본 데이터는 300개의 퓨처로 구성, 그 중 85개 선별  \n",
    "799만개의 데이터 중 45429개 균등 샘플링  \n",
    "INFANT_ALIVE_AT_REPORT 가 1인지 0인지 예측 하는 것이 목표.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.types as typ\n",
    "labels = [\n",
    "    ('INFANT_ALIVE_AT_REPORT', typ.StringType()),\n",
    "    ('BIRTH_YEAR', typ.IntegerType()),\n",
    "    ('BIRTH_MONTH', typ.IntegerType()),\n",
    "    ('BIRTH_PLACE', typ.StringType()),\n",
    "    ('MOTHER_AGE_YEARS', typ.IntegerType()),\n",
    "    ('MOTHER_RACE_6CODE', typ.StringType()),\n",
    "    ('MOTHER_EDUCATION', typ.StringType()),\n",
    "    ('FATHER_COMBINED_AGE', typ.IntegerType()),\n",
    "    ('FATHER_EDUCATION', typ.StringType()),\n",
    "    ('MONTH_PRECARE_RECODE', typ.StringType()),\n",
    "    ('CIG_BEFORE', typ.IntegerType()),\n",
    "    ('CIG_1_TRI', typ.IntegerType()),\n",
    "    ('CIG_2_TRI', typ.IntegerType()),\n",
    "    ('CIG_3_TRI', typ.IntegerType()),\n",
    "    ('MOTHER_HEIGHT_IN', typ.IntegerType()),\n",
    "    ('MOTHER_BMI_RECODE', typ.IntegerType()),\n",
    "    ('MOTHER_PRE_WEIGHT', typ.IntegerType()),\n",
    "    ('MOTHER_DELIVERY_WEIGHT', typ.IntegerType()),\n",
    "    ('MOTHER_WEIGHT_GAIN', typ.IntegerType()),\n",
    "    ('DIABETES_PRE', typ.StringType()),\n",
    "    ('DIABETES_GEST', typ.StringType()),\n",
    "    ('HYP_TENS_PRE', typ.StringType()),\n",
    "    ('HYP_TENS_GEST', typ.StringType()),\n",
    "    ('PREV_BIRTH_PRETERM', typ.StringType()),\n",
    "    ('NO_RISK', typ.StringType()),\n",
    "    ('NO_INFECTIONS_REPORTED', typ.StringType()),\n",
    "    ('LABOR_IND', typ.StringType()),\n",
    "    ('LABOR_AUGM', typ.StringType()),\n",
    "    ('STEROIDS', typ.StringType()),\n",
    "    ('ANTIBIOTICS', typ.StringType()),\n",
    "    ('ANESTHESIA', typ.StringType()),\n",
    "    ('DELIV_METHOD_RECODE_COMB', typ.StringType()),\n",
    "    ('ATTENDANT_BIRTH', typ.StringType()),\n",
    "    ('APGAR_5', typ.IntegerType()),\n",
    "    ('APGAR_5_RECODE', typ.StringType()),\n",
    "    ('APGAR_10', typ.IntegerType()),\n",
    "    ('APGAR_10_RECODE', typ.StringType()),\n",
    "    ('INFANT_SEX', typ.StringType()),\n",
    "    ('OBSTETRIC_GESTATION_WEEKS', typ.IntegerType()),\n",
    "    ('INFANT_WEIGHT_GRAMS', typ.IntegerType()),\n",
    "    ('INFANT_ASSIST_VENTI', typ.StringType()),\n",
    "    ('INFANT_ASSIST_VENTI_6HRS', typ.StringType()),\n",
    "    ('INFANT_NICU_ADMISSION', typ.StringType()),\n",
    "    ('INFANT_SURFACANT', typ.StringType()),\n",
    "    ('INFANT_ANTIBIOTICS', typ.StringType()),\n",
    "    ('INFANT_SEIZURES', typ.StringType()),\n",
    "    ('INFANT_NO_ABNORMALITIES', typ.StringType()),\n",
    "    ('INFANT_ANCEPHALY', typ.StringType()),\n",
    "    ('INFANT_MENINGOMYELOCELE', typ.StringType()),\n",
    "    ('INFANT_LIMB_REDUCTION', typ.StringType()),\n",
    "    ('INFANT_DOWN_SYNDROME', typ.StringType()),\n",
    "    ('INFANT_SUSPECTED_CHROMOSOMAL_DISORDER', typ.StringType()),\n",
    "    ('INFANT_NO_CONGENITAL_ANOMALIES_CHECKED', typ.StringType()),\n",
    "    ('INFANT_BREASTFED', typ.StringType())\n",
    "]\n",
    "\n",
    "schema = typ.StructType([typ.StructField(e[0], e[1], False) for e in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "births = spark.read.csv('./data/births_train.csv.gz', header=True, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(births)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- INFANT_ALIVE_AT_REPORT: string (nullable = true)\n",
      " |-- BIRTH_YEAR: integer (nullable = true)\n",
      " |-- BIRTH_MONTH: integer (nullable = true)\n",
      " |-- BIRTH_PLACE: string (nullable = true)\n",
      " |-- MOTHER_AGE_YEARS: integer (nullable = true)\n",
      " |-- MOTHER_RACE_6CODE: string (nullable = true)\n",
      " |-- MOTHER_EDUCATION: string (nullable = true)\n",
      " |-- FATHER_COMBINED_AGE: integer (nullable = true)\n",
      " |-- FATHER_EDUCATION: string (nullable = true)\n",
      " |-- MONTH_PRECARE_RECODE: string (nullable = true)\n",
      " |-- CIG_BEFORE: integer (nullable = true)\n",
      " |-- CIG_1_TRI: integer (nullable = true)\n",
      " |-- CIG_2_TRI: integer (nullable = true)\n",
      " |-- CIG_3_TRI: integer (nullable = true)\n",
      " |-- MOTHER_HEIGHT_IN: integer (nullable = true)\n",
      " |-- MOTHER_BMI_RECODE: integer (nullable = true)\n",
      " |-- MOTHER_PRE_WEIGHT: integer (nullable = true)\n",
      " |-- MOTHER_DELIVERY_WEIGHT: integer (nullable = true)\n",
      " |-- MOTHER_WEIGHT_GAIN: integer (nullable = true)\n",
      " |-- DIABETES_PRE: string (nullable = true)\n",
      " |-- DIABETES_GEST: string (nullable = true)\n",
      " |-- HYP_TENS_PRE: string (nullable = true)\n",
      " |-- HYP_TENS_GEST: string (nullable = true)\n",
      " |-- PREV_BIRTH_PRETERM: string (nullable = true)\n",
      " |-- NO_RISK: string (nullable = true)\n",
      " |-- NO_INFECTIONS_REPORTED: string (nullable = true)\n",
      " |-- LABOR_IND: string (nullable = true)\n",
      " |-- LABOR_AUGM: string (nullable = true)\n",
      " |-- STEROIDS: string (nullable = true)\n",
      " |-- ANTIBIOTICS: string (nullable = true)\n",
      " |-- ANESTHESIA: string (nullable = true)\n",
      " |-- DELIV_METHOD_RECODE_COMB: string (nullable = true)\n",
      " |-- ATTENDANT_BIRTH: string (nullable = true)\n",
      " |-- APGAR_5: integer (nullable = true)\n",
      " |-- APGAR_5_RECODE: string (nullable = true)\n",
      " |-- APGAR_10: integer (nullable = true)\n",
      " |-- APGAR_10_RECODE: string (nullable = true)\n",
      " |-- INFANT_SEX: string (nullable = true)\n",
      " |-- OBSTETRIC_GESTATION_WEEKS: integer (nullable = true)\n",
      " |-- INFANT_WEIGHT_GRAMS: integer (nullable = true)\n",
      " |-- INFANT_ASSIST_VENTI: string (nullable = true)\n",
      " |-- INFANT_ASSIST_VENTI_6HRS: string (nullable = true)\n",
      " |-- INFANT_NICU_ADMISSION: string (nullable = true)\n",
      " |-- INFANT_SURFACANT: string (nullable = true)\n",
      " |-- INFANT_ANTIBIOTICS: string (nullable = true)\n",
      " |-- INFANT_SEIZURES: string (nullable = true)\n",
      " |-- INFANT_NO_ABNORMALITIES: string (nullable = true)\n",
      " |-- INFANT_ANCEPHALY: string (nullable = true)\n",
      " |-- INFANT_MENINGOMYELOCELE: string (nullable = true)\n",
      " |-- INFANT_LIMB_REDUCTION: string (nullable = true)\n",
      " |-- INFANT_DOWN_SYNDROME: string (nullable = true)\n",
      " |-- INFANT_SUSPECTED_CHROMOSOMAL_DISORDER: string (nullable = true)\n",
      " |-- INFANT_NO_CONGENITAL_ANOMALIES_CHECKED: string (nullable = true)\n",
      " |-- INFANT_BREASTFED: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "births.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    'INFANT_ALIVE_AT_REPORT', \n",
    "    'BIRTH_PLACE', \n",
    "    'MOTHER_AGE_YEARS', \n",
    "    'FATHER_COMBINED_AGE', \n",
    "    'CIG_BEFORE', \n",
    "    'CIG_1_TRI', \n",
    "    'CIG_2_TRI', \n",
    "    'CIG_3_TRI', \n",
    "    'MOTHER_HEIGHT_IN', \n",
    "    'MOTHER_PRE_WEIGHT', \n",
    "    'MOTHER_DELIVERY_WEIGHT', \n",
    "    'MOTHER_WEIGHT_GAIN', \n",
    "    'DIABETES_PRE', \n",
    "    'DIABETES_GEST', \n",
    "    'HYP_TENS_PRE', \n",
    "    'HYP_TENS_GEST', \n",
    "    'PREV_BIRTH_PRETERM'\n",
    "]\n",
    "\n",
    "births_trimmed = births.select(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(INFANT_ALIVE_AT_REPORT='N', BIRTH_PLACE='1', MOTHER_AGE_YEARS=29, FATHER_COMBINED_AGE=99, CIG_BEFORE=99, CIG_1_TRI=99, CIG_2_TRI=99, CIG_3_TRI=99, MOTHER_HEIGHT_IN=99, MOTHER_PRE_WEIGHT=999, MOTHER_DELIVERY_WEIGHT=999, MOTHER_WEIGHT_GAIN=99, DIABETES_PRE='N', DIABETES_GEST='N', HYP_TENS_PRE='N', HYP_TENS_GEST='N', PREV_BIRTH_PRETERM='N')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "births_trimmed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋에는 Yes/No/Unkown값을 가진 피처들이 매우 많음.  \n",
    "Yes는 1, 나머지는 0으로 변환  \n",
    "\n",
    "어머니의 흡연량 관련 레코드 :\n",
    "0 : 임신 기간 동안 금연  \n",
    "1-97 : 한개 ~ 97개 사이  \n",
    "98 : 98개 이상  \n",
    "99 : 알 수 없음  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y : yes\n",
    "# N : no\n",
    "# U : unkown\n",
    "recode_dictionary = {\n",
    "    'YNU': {\n",
    "        'Y': 1,\n",
    "        'N': 2,\n",
    "        'U': 0\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as func\n",
    "\n",
    "def recode(col, key):        \n",
    "    return recode_dictionary[key][col] \n",
    "\n",
    "def correct_cig(feat):\n",
    "    return func \\\n",
    "        .when(func.col(feat) != 99, func.col(feat))\\\n",
    "        .otherwise(0)\n",
    "\n",
    "rec_integer = func.udf(recode, typ.IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "births_transformed = births_trimmed \\\n",
    "    .withColumn('CIG_BEFORE', correct_cig('CIG_BEFORE'))\\\n",
    "    .withColumn('CIG_1_TRI', correct_cig('CIG_1_TRI'))\\\n",
    "    .withColumn('CIG_2_TRI', correct_cig('CIG_2_TRI'))\\\n",
    "    .withColumn('CIG_3_TRI', correct_cig('CIG_3_TRI'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('INFANT_ALIVE_AT_REPORT', StringType),\n",
       " ('BIRTH_PLACE', StringType),\n",
       " ('MOTHER_AGE_YEARS', IntegerType),\n",
       " ('FATHER_COMBINED_AGE', IntegerType),\n",
       " ('CIG_BEFORE', IntegerType),\n",
       " ('CIG_1_TRI', IntegerType),\n",
       " ('CIG_2_TRI', IntegerType),\n",
       " ('CIG_3_TRI', IntegerType),\n",
       " ('MOTHER_HEIGHT_IN', IntegerType),\n",
       " ('MOTHER_PRE_WEIGHT', IntegerType),\n",
       " ('MOTHER_DELIVERY_WEIGHT', IntegerType),\n",
       " ('MOTHER_WEIGHT_GAIN', IntegerType),\n",
       " ('DIABETES_PRE', StringType),\n",
       " ('DIABETES_GEST', StringType),\n",
       " ('HYP_TENS_PRE', StringType),\n",
       " ('HYP_TENS_GEST', StringType),\n",
       " ('PREV_BIRTH_PRETERM', StringType)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [(col.name, col.dataType) for col in births_trimmed.schema]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "YNU_cols = []\n",
    "for i, s in enumerate(cols):\n",
    "    if s[1] == typ.StringType():\n",
    "        dis = births.select(s[0]) \\\n",
    "            .distinct() \\\n",
    "            .rdd \\\n",
    "            .map(lambda row: row[0]) \\\n",
    "            .collect()\n",
    "\n",
    "        if 'Y' in dis:\n",
    "            YNU_cols.append(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Y', 'N']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "births.select('INFANT_ALIVE_AT_REPORT') \\\n",
    "            .distinct() \\\n",
    "            .rdd \\\n",
    "            .map(lambda row: row[0]) \\\n",
    "            .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7', '3', '5', '6', '9', '1', '4', '2']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "births.select('BIRTH_PLACE') \\\n",
    "            .distinct() \\\n",
    "            .rdd \\\n",
    "            .map(lambda row: row[0]) \\\n",
    "            .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(INFANT_NICU_ADMISSION='Y', INFANT_NICU_ADMISSION_RECODE=1),\n",
       " Row(INFANT_NICU_ADMISSION='Y', INFANT_NICU_ADMISSION_RECODE=1),\n",
       " Row(INFANT_NICU_ADMISSION='U', INFANT_NICU_ADMISSION_RECODE=0),\n",
       " Row(INFANT_NICU_ADMISSION='N', INFANT_NICU_ADMISSION_RECODE=2),\n",
       " Row(INFANT_NICU_ADMISSION='U', INFANT_NICU_ADMISSION_RECODE=0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "births.select([\n",
    "    'INFANT_NICU_ADMISSION', rec_integer('INFANT_NICU_ADMISSION', func.lit('YNU')) \\\n",
    "                              .alias('INFANT_NICU_ADMISSION_RECODE')\n",
    "]).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "exprs_YNU = [\n",
    "    rec_integer(x, func.lit('YNU')).alias(x)\n",
    "    if x in YNU_cols\n",
    "    else x\n",
    "    for x in births_transformed.columns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "births_transformed = births_transformed.select(exprs_YNU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.mllib.stat as st\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\n",
    "    'MOTHER_AGE_YEARS',\n",
    "    'FATHER_COMBINED_AGE',\n",
    "    'CIG_BEFORE',\n",
    "    'CIG_1_TRI',\n",
    "    'CIG_2_TRI',\n",
    "    'CIG_3_TRI',\n",
    "    'MOTHER_HEIGHT_IN',\n",
    "    'MOTHER_PRE_WEIGHT',\n",
    "    'MOTHER_DELIVERY_WEIGHT',\n",
    "    'MOTHER_WEIGHT_GAIN'\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_rdd = births_transformed \\\n",
    "        .select(numeric_cols) \\\n",
    "        .rdd \\\n",
    "        .map(lambda row : [e for e in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mllib_stats = st.Statistics.colStats(numeric_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOTHER_AGE_YEARS: \t28.30 \t 6.08\n",
      "FATHER_COMBINED_AGE: \t44.55 \t 27.55\n",
      "CIG_BEFORE: \t1.43 \t 5.18\n",
      "CIG_1_TRI: \t0.91 \t 3.83\n",
      "CIG_2_TRI: \t0.70 \t 3.31\n",
      "CIG_3_TRI: \t0.58 \t 3.11\n",
      "MOTHER_HEIGHT_IN: \t65.12 \t 6.45\n",
      "MOTHER_PRE_WEIGHT: \t214.50 \t 210.21\n",
      "MOTHER_DELIVERY_WEIGHT: \t223.63 \t 180.01\n",
      "MOTHER_WEIGHT_GAIN: \t30.74 \t 26.23\n"
     ]
    }
   ],
   "source": [
    "for col, m, v in zip(numeric_cols,\n",
    "                      mllib_stats.mean(),\n",
    "                      mllib_stats.variance()):\n",
    "    print('{0}: \\t{1:.2f} \\t {2:.2f}'.format(col, m, np.sqrt(v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "colStats() 함수는 기술통계를 샘플링해서 계산.  \n",
    "실제 데이터에서는 큰 문제는 없다. 데이터셋이 100개 미만일 겨웅에는 문제가 될수 있다.  \n",
    "colStats() 함수는 RDD 데이터를 취해 기술통계를 계산한다.  \n",
    "MultivariateStatisticalSummary 객체를 리턴  \n",
    "\n",
    "- count() : 데이터 행 갯수\n",
    "- max() : 최댓값\n",
    "- mean() : 평균\n",
    "- min() : 최솟값\n",
    "- numNonzeros() : 0이 아닌 값의 수\n",
    "- variance() : 분산\n",
    "- norml1 : L1-norm 값\n",
    "- norml2 : L2-norm 값\n",
    "\n",
    "L2 Loss는 직관적으로 오차의 제곱을 더함, Outlier에 큰 영향을 받는다.  \n",
    "L1 Loss가 L2 Loss에 비해 Outlier에 대하여 더 Robust하다.  \n",
    "\n",
    "Outlier가 적당히 무시되길 바라면 L1 Loss를, Outlier에 신경을 써야 한다면 L2 Loss를 사용  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [e for e in births_transformed.columns\n",
    "                    if e not in numeric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_rdd =births_transformed \\\n",
    "            . select(categorical_cols) \\\n",
    "            . rdd \\\n",
    "            . map(lambda row : [ e for e in row])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFANT_ALIVE_AT_REPORT [(1, 23349), (2, 22080)]\n",
      "BIRTH_PLACE [('1', 44558), ('4', 327), ('3', 224), ('2', 136), ('7', 91), ('5', 74), ('6', 11), ('9', 8)]\n",
      "DIABETES_PRE [(2, 44689), (1, 548), (0, 192)]\n",
      "DIABETES_GEST [(2, 43259), (1, 1978), (0, 192)]\n",
      "HYP_TENS_PRE [(2, 44156), (1, 1081), (0, 192)]\n",
      "HYP_TENS_GEST [(2, 43110), (1, 2127), (0, 192)]\n",
      "PREV_BIRTH_PRETERM [(2, 42896), (1, 2341), (0, 192)]\n"
     ]
    }
   ],
   "source": [
    "for i, col in enumerate(categorical_cols):\n",
    "    agg = categorical_rdd \\\n",
    "        .groupBy(lambda row: row[i]) \\\n",
    "        .map(lambda row: (row[0], len(row[1])))\n",
    "    print(col, sorted(agg.collect(),\n",
    "                     key=lambda e1: e1[1],\n",
    "                     reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = st.Statistics.corr(numeric_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOTHER_AGE_YEARS-to-MOTHER_AGE_YEARS: 1.00\n",
      "CIG_BEFORE-to-CIG_BEFORE: 1.00\n",
      "CIG_BEFORE-to-CIG_1_TRI: 0.83\n",
      "CIG_BEFORE-to-CIG_2_TRI: 0.72\n",
      "CIG_BEFORE-to-CIG_3_TRI: 0.62\n",
      "CIG_1_TRI-to-CIG_BEFORE: 0.83\n",
      "CIG_1_TRI-to-CIG_1_TRI: 1.00\n",
      "CIG_1_TRI-to-CIG_2_TRI: 0.87\n",
      "CIG_1_TRI-to-CIG_3_TRI: 0.76\n",
      "CIG_2_TRI-to-CIG_BEFORE: 0.72\n",
      "CIG_2_TRI-to-CIG_1_TRI: 0.87\n",
      "CIG_2_TRI-to-CIG_2_TRI: 1.00\n",
      "CIG_2_TRI-to-CIG_3_TRI: 0.89\n",
      "CIG_3_TRI-to-CIG_BEFORE: 0.62\n",
      "CIG_3_TRI-to-CIG_1_TRI: 0.76\n",
      "CIG_3_TRI-to-CIG_2_TRI: 0.89\n",
      "CIG_3_TRI-to-CIG_3_TRI: 1.00\n",
      "MOTHER_HEIGHT_IN-to-MOTHER_HEIGHT_IN: 1.00\n",
      "MOTHER_PRE_WEIGHT-to-MOTHER_PRE_WEIGHT: 1.00\n",
      "MOTHER_PRE_WEIGHT-to-MOTHER_DELIVERY_WEIGHT: 0.54\n",
      "MOTHER_PRE_WEIGHT-to-MOTHER_WEIGHT_GAIN: 0.65\n",
      "MOTHER_DELIVERY_WEIGHT-to-MOTHER_PRE_WEIGHT: 0.54\n",
      "MOTHER_DELIVERY_WEIGHT-to-MOTHER_DELIVERY_WEIGHT: 1.00\n",
      "MOTHER_DELIVERY_WEIGHT-to-MOTHER_WEIGHT_GAIN: 0.60\n",
      "MOTHER_WEIGHT_GAIN-to-MOTHER_PRE_WEIGHT: 0.65\n",
      "MOTHER_WEIGHT_GAIN-to-MOTHER_DELIVERY_WEIGHT: 0.60\n",
      "MOTHER_WEIGHT_GAIN-to-MOTHER_WEIGHT_GAIN: 1.00\n"
     ]
    }
   ],
   "source": [
    "for i, el in enumerate(corrs > 0.5):\n",
    "    correlated = [\n",
    "        (numeric_cols[j], corrs[i][j])\n",
    "        for j, e in enumerate(el)\n",
    "        if e == 1.0 and j != 1\n",
    "    ]\n",
    "    if len(correlated) > 0:\n",
    "        for e in correlated:\n",
    "            print('{0}-to-{1}: {2:.2f}'.format(numeric_cols[i], e[0], e[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대립가설에 대한 correlation  \n",
    "=> 대립가설이 성립 => 나의 가설은 기각!!  \n",
    "그렇다고 데이터가 부족하다면 무작정 지우지는 말아야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = [\n",
    "    'INFANT_ALIVE_AT_REPORT',\n",
    "    'BIRTH_PLACE',\n",
    "    'MOTHER_AGE_YEARS',\n",
    "    'FATHER_COMBINED_AGE',\n",
    "    'CIG_1_TRI',\n",
    "    'MOTHER_HEIGHT_IN',\n",
    "    'MOTHER_PRE_WEIGHT',\n",
    "    'DIABETES_PRE',\n",
    "    'DIABETES_GEST',\n",
    "    'HYP_TENS_PRE',\n",
    "    'HYP_TENS_GEST',\n",
    "    'PREV_BIRTH_PRETERM'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "births_transformed = births_transformed.select([e for e in features_to_keep])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.mllib.linalg as ln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### 카이제곱테스트 (chiSqTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIRTH_PLACE 0.0\n",
      "DIABETES_PRE 0.0\n",
      "DIABETES_GEST 0.0\n",
      "HYP_TENS_PRE 0.0\n",
      "HYP_TENS_GEST 0.0\n",
      "PREV_BIRTH_PRETERM 0.0\n"
     ]
    }
   ],
   "source": [
    "for cat in categorical_cols[1:]:\n",
    "    agg = births_transformed \\\n",
    "        .groupBy('INFANT_ALIVE_AT_REPORT') \\\n",
    "        .pivot(cat) \\\n",
    "        .count()\n",
    "    agg_rdd = agg \\\n",
    "        .rdd \\\n",
    "        .map(lambda row: (row[1:])) \\\n",
    "        .flatMap(lambda row: [0 if e == None else e for e in row]) \\\n",
    "        .collect()\n",
    "    row_length = len(agg.collect()[0]) -1\n",
    "    agg = ln.Matrices.dense(row_length, 2, agg_rdd)\n",
    "    \n",
    "    test = st.Statistics.chiSqTest(agg)\n",
    "    print(cat, round(test.pValue, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Matrics.dense() 함수  \n",
    "첫번째 : 행렬에서 행의 수  \n",
    "두번째 : 카테고리 고유 값의 수  \n",
    "세번째 : 행렬로 변환할 값들에 대한 리스트  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.mllib.feature as ft\n",
    "import pyspark.mllib.regression as reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashing = ft.HashingTF(7)\n",
    "births_hashed = births_transformed \\\n",
    "        .rdd \\\n",
    "        .map(lambda row: [\n",
    "            list(hashing.transform(row[1]).toArray())\n",
    "                if col == 'BIRTH_PLACE'\n",
    "                else row[i]\n",
    "            for i, col in enumerate(features_to_keep)]) \\\n",
    "        .map(lambda row: [[e] if type(e) == int else e for e in row]) \\\n",
    "        .map(lambda row: [item for sublist in row for item in sublist]) \\\n",
    "        .map(lambda row: reg.LabeledPoint(row[0], ln.Vectors.dense(row[1:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training & test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "births_train, births_test = births_hashed.randomSplit([0.6,0.4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o685.trainLogisticRegressionModelWithLBFGS.\n: org.apache.spark.SparkException: Multinomial models contain a matrix of coefficients, use coefficientMatrix instead.\r\n\tat org.apache.spark.ml.classification.LogisticRegressionModel.coefficients(LogisticRegression.scala:955)\r\n\tat org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS.runWithMlLogisticRegression$1(LogisticRegression.scala:455)\r\n\tat org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS.run(LogisticRegression.scala:459)\r\n\tat org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS.run(LogisticRegression.scala:425)\r\n\tat org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS.run(LogisticRegression.scala:355)\r\n\tat org.apache.spark.mllib.api.python.PythonMLLibAPI.trainRegressionModel(PythonMLLibAPI.scala:92)\r\n\tat org.apache.spark.mllib.api.python.PythonMLLibAPI.trainLogisticRegressionModelWithLBFGS(PythonMLLibAPI.scala:308)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-25b7b786f68b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegressionWithLBFGS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mLR_Model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegressionWithLBFGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbirths_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\mllib\\classification.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(cls, data, iterations, initialWeights, regParam, regType, intercept, corrections, tolerance, validateData, numClasses)\u001b[0m\n\u001b[0;32m    400\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m                     \u001b[0minitialWeights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnumClasses\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_regression_train_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLogisticRegressionModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitialWeights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\mllib\\regression.py\u001b[0m in \u001b[0;36m_regression_train_wrapper\u001b[1;34m(train_func, modelClass, data, initial_weights)\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodelClass\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mLogisticRegressionModel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         weights, intercept, numFeatures, numClasses = train_func(\n\u001b[1;32m--> 217\u001b[1;33m             data, _convert_to_vector(initial_weights))\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodelClass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumFeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumClasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\mllib\\classification.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(rdd, i)\u001b[0m\n\u001b[0;32m    390\u001b[0m             return callMLlibFunc(\"trainLogisticRegressionModelWithLBFGS\", rdd, int(iterations), i,\n\u001b[0;32m    391\u001b[0m                                  \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregParam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintercept\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrections\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m                                  float(tolerance), bool(validateData), int(numClasses))\n\u001b[0m\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minitialWeights\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\mllib\\common.py\u001b[0m in \u001b[0;36mcallMLlibFunc\u001b[1;34m(name, *args)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[0mapi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPythonMLLibAPI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcallJavaFunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\mllib\\common.py\u001b[0m in \u001b[0;36mcallJavaFunc\u001b[1;34m(sc, func, *args)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;34m\"\"\" Call Java Function \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_java2py\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1257\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o685.trainLogisticRegressionModelWithLBFGS.\n: org.apache.spark.SparkException: Multinomial models contain a matrix of coefficients, use coefficientMatrix instead.\r\n\tat org.apache.spark.ml.classification.LogisticRegressionModel.coefficients(LogisticRegression.scala:955)\r\n\tat org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS.runWithMlLogisticRegression$1(LogisticRegression.scala:455)\r\n\tat org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS.run(LogisticRegression.scala:459)\r\n\tat org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS.run(LogisticRegression.scala:425)\r\n\tat org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS.run(LogisticRegression.scala:355)\r\n\tat org.apache.spark.mllib.api.python.PythonMLLibAPI.trainRegressionModel(PythonMLLibAPI.scala:92)\r\n\tat org.apache.spark.mllib.api.python.PythonMLLibAPI.trainLogisticRegressionModelWithLBFGS(PythonMLLibAPI.scala:308)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "LR_Model = LogisticRegressionWithLBFGS.train(births_train, iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_results = (\n",
    "        births_test.map(lambda row: eow.label) \\\n",
    "        .zip(LR_Model\n",
    "            .predict(births_test \\\n",
    "                    .map(lambda row: row.features)))\n",
    "        ).map(lambda row:(row[0], row[1] * 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
